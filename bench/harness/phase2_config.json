{
  "models": {
    "lfm2.5-thinking:1.2b": {
      "name": "LFM2.5-1.2B",
      "arch": "State-space hybrid",
      "system_prompt": "You are a helpful assistant with access to tools. When you need to call a tool, use bracket notation: [tool_name(arg=\"value\")].",
      "temperature": 0.0,
      "output_format": "bracket_notation",
      "notes": "Prefers bracket output. State-space models handle multi-turn well.",
      "variants": {
        "atomic": {
          "system": "When you need a tool, use: [tool_name(arg=\"value\")]",
          "max_tokens": 500,
          "description": "Original bracket format for atomic prompts"
        },
        "extended": {
          "system": "You are a helpful assistant. Remember conversation context. When tools are needed, use: [tool_name(arg=\"value\")]",
          "max_tokens": 1000,
          "description": "Extended with context awareness for multi-turn"
        }
      }
    },
    "mistral:7b": {
      "name": "Mistral 7B",
      "arch": "Transformer (7B)",
      "system_prompt": "You are a helpful assistant. Call tools when needed to fulfill user requests.",
      "temperature": 0.0,
      "output_format": "native_tools_api",
      "notes": "Transformer. Sometimes verbose. Add explicit instruction to be concise.",
      "variants": {
        "atomic": {
          "system": "You are a helpful assistant. Call tools when the user asks. Be concise.",
          "max_tokens": 500,
          "description": "Baseline with conciseness instruction"
        },
        "extended": {
          "system": "You are a helpful assistant. Pay attention to conversation context. Maintain state across turns. Call tools only when truly needed. Be concise.",
          "max_tokens": 1000,
          "description": "Extended with explicit state awareness + restraint reminder"
        }
      }
    },
    "gpt-oss:latest": {
      "name": "GPT-OSS",
      "arch": "Unknown (13GB, likely transformer)",
      "system_prompt": "You are a helpful assistant with tool access.",
      "temperature": 0.0,
      "output_format": "native_tools_api",
      "notes": "Excellent on atomic validation (87.5% before timeout). Fast judgment.",
      "variants": {
        "atomic": {
          "system": "You are a helpful assistant. Use tools to answer user questions accurately.",
          "max_tokens": 500,
          "description": "Standard variant"
        },
        "extended": {
          "system": "You are a helpful assistant. Remember conversation context. Use tools appropriately based on what the user actually asks for, not contextual hints.",
          "max_tokens": 1000,
          "description": "Extended with context + explicit instruction to ignore contextual hints"
        }
      }
    },
    "qwen2.5:3b": {
      "name": "Qwen2.5 3B",
      "arch": "Transformer (3B)",
      "system_prompt": "You are a helpful assistant. Use tools to answer user questions.",
      "temperature": 0.0,
      "output_format": "native_tools_api",
      "notes": "Baseline 3B. Poor restraint (false positives P6, P9). Needs explicit safety instructions.",
      "variants": {
        "atomic": {
          "system": "You are a helpful assistant. ONLY call tools when the user explicitly asks. Do not call tools just because they are available. Be strict: if unsure, do not call.",
          "max_tokens": 500,
          "description": "Safety-focused: explicit restraint instructions"
        },
        "extended": {
          "system": "You are a helpful assistant. ONLY call tools when the user explicitly requests them. Ignore contextual hints. Maintain conversation history. Be very conservative with tool calls.",
          "max_tokens": 1000,
          "description": "Extended + strict safety"
        }
      }
    },
    "ministral-3:latest": {
      "name": "Ministral 3B",
      "arch": "Transformer (3B, Mistral optimized)",
      "system_prompt": "You are a helpful assistant.",
      "temperature": 0.0,
      "output_format": "native_tools_api",
      "notes": "Smaller variant. Unknown performance. Test as candidate.",
      "variants": {
        "atomic": {
          "system": "You are a helpful assistant. Call tools only when needed.",
          "max_tokens": 500,
          "description": "Baseline for new model"
        },
        "extended": {
          "system": "You are a helpful assistant. Track conversation context. Call tools sparingly.",
          "max_tokens": 1000,
          "description": "Extended variant"
        }
      }
    },
    "qwen3.5:35b": {
      "name": "Qwen3.5-35B",
      "arch": "Transformer (Qwen3.5)",
      "system_prompt": "You are a helpful assistant. Use tool calls only when needed to satisfy the user request.",
      "temperature": 0.0,
      "output_format": "native_tools_api",
      "notes": "35B model - uses native Ollama tools API, not bracket notation. High latency (~35s), needs 120s timeout.",
      "variants": {
        "atomic": {
          "system": "You are a helpful assistant. Call tools when required by the user request. Avoid unnecessary tool calls.",
          "max_tokens": 500,
          "description": "Native tool-calling variant for Qwen3.5 atomic prompts"
        },
        "extended": {
          "system": "You are a helpful assistant. Track conversation context and call tools only when necessary for the user request.",
          "max_tokens": 1000,
          "description": "Native tool-calling variant for Qwen3.5 extended prompts"
        }
      },
      "timeout_seconds": 120
    },
    "glm-4.7-flash:latest": {
      "name": "GLM-4.7 Flash",
      "arch": "Transformer (GLM 4.7 Flash)",
      "system_prompt": "You are a helpful assistant. Call tools only when needed.",
      "temperature": 0.0,
      "output_format": "native_tools_api",
      "notes": "Local Ollama model. Added for core harness compatibility and tok/s tracking.",
      "variants": {
        "atomic": {
          "system": "You are a helpful assistant. Call tools only when the user request requires them.",
          "max_tokens": 500,
          "description": "Baseline atomic variant for GLM tool-calling"
        },
        "extended": {
          "system": "You are a helpful assistant. Track conversation context. Call tools only when explicitly useful and necessary.",
          "max_tokens": 1000,
          "description": "Extended variant with context + restraint reminders"
        }
      },
      "timeout_seconds": 90
    }
  },
  "early_exit": {
    "atomic_fail_threshold": 0.5,
    "restraint_fail_threshold": 0.0,
    "rules": [
      {
        "id": "high_failure",
        "condition": "accuracy < 0.50 on P1-P12",
        "action": "SKIP extended tests",
        "reason": "Too low to warrant P13-P30 investment"
      },
      {
        "id": "zero_restraint",
        "condition": "restraint_score == 0.0",
        "action": "FLAG UNSAFE, skip advanced tests",
        "reason": "Model calls tools when it shouldn't - production risk"
      },
      {
        "id": "excellent_atomic",
        "condition": "accuracy >= 0.90 on P1-P12",
        "action": "PRIORITIZE extended tests",
        "reason": "Strong candidate for multi-turn evaluation"
      }
    ]
  },
  "timeout_seconds": 60
}