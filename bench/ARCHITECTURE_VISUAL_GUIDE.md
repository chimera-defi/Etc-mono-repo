# Architecture Visual Guide

Quick reference diagrams for the self-optimizing benchmark harness.

---

## 1. System Layers

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  LAYER 4: HUMAN INTERFACE                                        â”‚
â”‚  â”Œâ”€ SELF_OPTIMIZING_REPORT.md (human-readable)                  â”‚
â”‚  â”œâ”€ Routing recommendations (feedback_loop.json)                 â”‚
â”‚  â””â”€ Decision audit trail (routing_decisions.log)                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  LAYER 3: ORCHESTRATION                                          â”‚
â”‚  â”Œâ”€ meta_harness_loop.py        (multi-cycle optimization)       â”‚
â”‚  â”œâ”€ routing_enforcer.py         (apply recommendations)          â”‚
â”‚  â”œâ”€ harness_feedback_loop.py    (generate recommendations)       â”‚
â”‚  â””â”€ meta_loop_history.json      (long-term trends)               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  LAYER 2: EVALUATION                                             â”‚
â”‚  â”Œâ”€ benchmark_supervisor.py     (7-run variance tracking)        â”‚
â”‚  â”œâ”€ self_optimizing_policy.py   (decision gates)                 â”‚
â”‚  â”œâ”€ supervisor_runs/            (run artifacts)                  â”‚
â”‚  â””â”€ manifest.json               (variance analysis)              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  LAYER 1: EXECUTION                                              â”‚
â”‚  â”Œâ”€ run_benchmark.py            (single model execution)         â”‚
â”‚  â”œâ”€ Prompt suite (P1-P30)                                        â”‚
â”‚  â”œâ”€ Model invocation (LLM API)                                   â”‚
â”‚  â””â”€ Result JSON (accuracy, latency, failures)                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  INFRASTRUCTURE                                                  â”‚
â”‚  â”œâ”€ Ollama (local models: LFM, Qwen, Ministral)                 â”‚
â”‚  â”œâ”€ Anthropic API (Claude Haiku, Sonnet, Opus)                  â”‚
â”‚  â””â”€ OpenAI API (fallback, if configured)                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 2. Data Flow (Single Cycle)

```
USER COMMAND
    â”‚
    â”œâ”€ python3 meta_harness_loop.py
    â”‚
    â”œâ”€ DISCOVER CANDIDATES
    â”‚   â””â”€ Generate: (model Ã— phase Ã— variant Ã— timeout Ã— retries Ã— isolate)
    â”‚       Example: lfm2.5:atomic:native_api:60s:r1:i0
    â”‚
    â”œâ”€ EVALUATE (FOR EACH CANDIDATE)
    â”‚   â”‚
    â”‚   â””â”€ benchmark_supervisor.py (7 runs)
    â”‚       â”‚
    â”‚       â”œâ”€ RUN 1
    â”‚       â”‚   â””â”€ run_benchmark.py
    â”‚       â”‚       â””â”€ LLM INVOCATION (P1-P12)
    â”‚       â”‚           â””â”€ {accuracy: 0.667, latency: 30s, ...}
    â”‚       â”‚
    â”‚       â”œâ”€ RUN 2-7 (same)
    â”‚       â”‚
    â”‚       â””â”€ AGGREGATE
    â”‚           â””â”€ median_accuracy: 0.667
    â”‚           â””â”€ variance: 0.0117
    â”‚           â””â”€ latency_p50: 30s
    â”‚           â””â”€ pattern: [F,F,P,P,P,P,P]
    â”‚
    â”œâ”€ ANALYZE
    â”‚   â”‚
    â”‚   â””â”€ self_optimizing_policy.py
    â”‚       â”‚
    â”‚       â”œâ”€ Gate 1: min_samples >= 3? âœ“
    â”‚       â”œâ”€ Gate 2: variance <= 0.0025? âœ— (0.0117)
    â”‚       â”œâ”€ Gate 3: no regression? âœ“
    â”‚       â””â”€ Gate 4: restraint >= 0.80? âœ“
    â”‚
    â”‚       â””â”€ DECISION: HOLD (variance too high)
    â”‚
    â”œâ”€ RECOMMEND
    â”‚   â”‚
    â”‚   â””â”€ harness_feedback_loop.py
    â”‚       â”‚
    â”‚       â”œâ”€ Pattern detected: [F,F,P,P,P,P,P]
    â”‚       â”œâ”€ Root cause: Cold-start (infrastructure)
    â”‚       â””â”€ Recommendation: Enable warm-up
    â”‚
    â”‚       â””â”€ OUTPUT: harness_feedback.json
    â”‚
    â”œâ”€ ENFORCE
    â”‚   â”‚
    â”‚   â””â”€ routing_enforcer.py
    â”‚       â”‚
    â”‚       â”œâ”€ Read: harness_feedback.json
    â”‚       â”œâ”€ Convert: recommendations â†’ routing_config.json
    â”‚       â””â”€ Log: routing_decisions.log
    â”‚
    â”œâ”€ STORE HISTORY
    â”‚   â”‚
    â”‚   â””â”€ meta_loop_history.json (append)
    â”‚       â””â”€ {cycle: 1, baseline: ..., decisions: [...]}
    â”‚
    â””â”€ OUTPUT REPORT
        â”‚
        â””â”€ SELF_OPTIMIZING_REPORT.md (markdown)
            â””â”€ Human-readable summary + decisions

CYCLE N+1 STARTS: Use PROMOTED variant as new baseline
```

---

## 3. Variance Pattern Recognition

```
VARIANCE PATTERN DETECTION

Pattern A: Infrastructure Variance (Cold-Start)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Outcome: [F, F, P, P, P, P, P]  â”‚
â”‚ Frequency: 100% consistent       â”‚
â”‚ Pass rate: 71.4%                â”‚
â”‚                                 â”‚
â”‚ Interpretation:                 â”‚
â”‚ Runs 1-2: FAIL   â† Cold-start   â”‚
â”‚           (Ollama not in VRAM)   â”‚
â”‚ Runs 3-7: PASS   â† Warmed up    â”‚
â”‚           (Model loaded)         â”‚
â”‚                                 â”‚
â”‚ Solution: PRE-WARM model        â”‚
â”‚ Expected result: [P,P,P,P,P,P,P]â”‚
â”‚ New accuracy: 100%              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Pattern B: Capability Limit (No Variance)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Outcome: [F, F, F, F, F, F, F]  â”‚
â”‚ Frequency: 100% consistent       â”‚
â”‚ Pass rate: 0%                   â”‚
â”‚                                 â”‚
â”‚ Interpretation:                 â”‚
â”‚ All runs FAIL    â† Model limit  â”‚
â”‚ No variance      â† Deterministicâ”‚
â”‚                  (not noise)     â”‚
â”‚                                 â”‚
â”‚ Solution: ROUTE TO BETTER MODEL â”‚
â”‚ Expected result: [P,P,P,P,P,P,P]â”‚
â”‚ New accuracy: 100% (Haiku)      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Pattern C: Random Variance (Noise)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Outcome: [F, P, F, P, P, F, P]  â”‚
â”‚ Frequency: Random               â”‚
â”‚ Pass rate: 57%                  â”‚
â”‚                                 â”‚
â”‚ Interpretation:                 â”‚
â”‚ Unpredictable failures          â”‚
â”‚ Possible causes:                â”‚
â”‚  â€¢ Network noise               â”‚
â”‚  â€¢ Random timing issues        â”‚
â”‚  â€¢ Prompt context mixing       â”‚
â”‚                                 â”‚
â”‚ Solution: RETRY OPTIMIZATION    â”‚
â”‚ Expected: Increase retries      â”‚
â”‚ Or: Timeout adjustment          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 4. Routing Decision Tree

```
MODEL PHASE ROUTING

USER REQUEST
    â”‚
    â”œâ”€ Model: lfm2.5-thinking:1.2b
    â””â”€ Phase: atomic or extended?
        â”‚
        â”œâ”€ EXTENDED?
        â”‚   â”œâ”€ Check: Is model disabled for extended?
        â”‚   â”‚   â”‚
        â”‚   â”‚   â”œâ”€ YES (LFM, Qwen, etc.)
        â”‚   â”‚   â”‚   â””â”€ FALLBACK: claude-haiku âœ… (100% proven)
        â”‚   â”‚   â”‚       â””â”€ Log: "Routed to Haiku (0% baseline)"
        â”‚   â”‚   â”‚
        â”‚   â”‚   â””â”€ NO (Haiku, Opus)
        â”‚   â”‚       â””â”€ ALLOW: Execute directly âœ…
        â”‚   â”‚
        â”‚   â””â”€ RESULT: Extended ops always succeed
        â”‚
        â””â”€ ATOMIC?
            â”œâ”€ Check: Is model disabled for atomic?
            â”‚   â”‚
            â”‚   â”œâ”€ YES (e.g., broken model)
            â”‚   â”‚   â””â”€ FALLBACK: claude-haiku âœ…
            â”‚   â”‚
            â”‚   â””â”€ NO (LFM, Haiku, etc.)
            â”‚       â”œâ”€ Check: Does model need warm-up?
            â”‚       â”‚   â”‚
            â”‚       â”‚   â”œâ”€ YES (LFM shows cold-start)
            â”‚       â”‚   â”‚   â””â”€ ENABLE: --enable-warmup
            â”‚       â”‚   â”‚       â””â”€ Accuracy: 71.4% â†’ 100%
            â”‚       â”‚   â”‚
            â”‚       â”‚   â””â”€ NO (Haiku, etc.)
            â”‚       â”‚       â””â”€ EXECUTE: Directly
            â”‚       â”‚
            â”‚       â””â”€ RESULT: Atomic ops optimized
```

---

## 5. Improvement Cycle (Meta-Harness Loop)

```
IMPROVEMENT SPIRAL

                         Cycle N+1 Baseline
                    (best from Cycle N)
                              â–²
                              â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚                                                â”‚
    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
    â”‚  â”‚  CYCLE N+1                             â”‚   â”‚
    â”‚  â”‚  â”Œâ”€ New candidates vs improved baselineâ”‚   â”‚
    â”‚  â”‚  â”œâ”€ Measure: Can we beat Cycle N?     â”‚   â”‚
    â”‚  â”‚  â”œâ”€ Result: baseline â†’ X% (hopefully  â”‚   â”‚
    â”‚  â”‚  â”‚           higher than Cycle N)     â”‚   â”‚
    â”‚  â”‚  â””â”€ Learn: Which configs work best    â”‚   â”‚
    â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
    â”‚           â–²                                    â”‚
    â”‚           â”‚                                    â”‚
    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
    â”‚  â”‚  CYCLE N                                â”‚  â”‚
    â”‚  â”‚  â”Œâ”€ Baseline: 66.7% (native_api)      â”‚  â”‚
    â”‚  â”‚  â”œâ”€ Candidates: atomic, timeout, etc. â”‚  â”‚
    â”‚  â”‚  â”œâ”€ Evaluation: 4 specs Ã— 7 runs      â”‚  â”‚
    â”‚  â”‚  â”œâ”€ Policy gates: promote/hold/reject â”‚  â”‚
    â”‚  â”‚  â”œâ”€ Winner: atomic 83.3% â†’ PROMOTE   â”‚  â”‚
    â”‚  â”‚  â””â”€ Learn: variant matters!           â”‚  â”‚
    â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
    â”‚           â–²                                    â”‚
    â”‚           â”‚                                    â”‚
    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
    â”‚  â”‚  CYCLE 1 (Initial)                     â”‚  â”‚
    â”‚  â”‚  â”Œâ”€ Baseline: 66.7% (native_api)      â”‚  â”‚
    â”‚  â”‚  â”œâ”€ Candidates: try variants          â”‚  â”‚
    â”‚  â”‚  â”œâ”€ Evaluation: 12 specs Ã— 7 runs     â”‚  â”‚
    â”‚  â”‚  â”œâ”€ Policy gates: classify candidates â”‚  â”‚
    â”‚  â”‚  â”œâ”€ Winner: atomic 83.3% â†’ PROMOTE   â”‚  â”‚
    â”‚  â”‚  â””â”€ Learn: cold-start pattern found!  â”‚  â”‚
    â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
    â”‚           â–²                                    â”‚
    â”‚           â”‚                                    â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Improvement Curve:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

Accuracy (%)
100  â”‚                       â”Œâ”€ Ceiling (model limit)
     â”‚                       â”‚
  90 â”‚                   â”Œâ”€â”˜
     â”‚                â”Œâ”€â”˜
  80 â”‚            â”Œâ”€â”˜
     â”‚        â”Œâ”€â”˜ Cycle N+1 (Timeout optimization)
  70 â”‚    â”Œâ”€â”˜â”€ Cycle N (Variant optimization)
     â”‚   â”‚     Cycle 1 (Baseline + cold-start)
  60 â”‚   â”‚
     â”‚â”€â”€â”€â”´â”€â”€â”€â”´â”€â”€â”€â”´â”€â”€â”€â”´â”€â”€â”€â”´â”€â”€â”€â”´â”€â”€â”€â†’ Cycles
       1   2   3   4   5   6   7

Expected: Monotonic improvement until ceiling
```

---

## 6. Policy Gate Flow

```
POLICY GATE EVALUATION

Candidate Specification:
    â”‚
    â”œâ”€ Runs completed: 7
    â”œâ”€ Median accuracy: 0.833
    â”œâ”€ Accuracy variance: 0.0
    â”œâ”€ Median restraint: 1.0
    â””â”€ Baseline median accuracy: 0.667
        â”‚
        â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  GATE 1: Min Samples             â”‚
    â”‚  Required: >= 3                  â”‚
    â”‚  Observed: 7                     â”‚
    â”‚  Result: âœ“ PASS                  â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚
        â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  GATE 2: Variance Limit          â”‚
    â”‚  Required: <= 0.0025             â”‚
    â”‚  Observed: 0.0                   â”‚
    â”‚  Result: âœ“ PASS                  â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚
        â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  GATE 3: No Regression           â”‚
    â”‚  Required: >= baseline (0.667)   â”‚
    â”‚  Observed: 0.833                 â”‚
    â”‚  Result: âœ“ PASS (+16.6%)         â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚
        â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  GATE 4: Restraint Floor         â”‚
    â”‚  Required: >= 0.80               â”‚
    â”‚  Observed: 1.0                   â”‚
    â”‚  Result: âœ“ PASS                  â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚
        â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  DECISION: PROMOTE               â”‚
    â”‚                                  â”‚
    â”‚  New baseline = this candidate   â”‚
    â”‚  Candidate becomes default       â”‚
    â”‚  Previous baseline archived      â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 7. File Organization

```
/root/.openclaw/workspace/bench/
â”‚
â”œâ”€ CORE HARNESS
â”‚  â”œâ”€ run_benchmark.py           [Layer 1] Single model runner
â”‚  â”œâ”€ benchmark_supervisor.py    [Layer 2] Multi-run aggregator
â”‚  â”œâ”€ meta_harness_loop.py       [Layer 3] Cycle orchestrator
â”‚  â””â”€ routing_enforcer.py        [Layer 3] Routing applier (new)
â”‚
â”œâ”€ POLICY & DECISION LOGIC
â”‚  â”œâ”€ self_optimizing_policy.py  [Layer 2] Gate evaluation
â”‚  â””â”€ harness_feedback_loop.py   [Layer 3] Recommendation generator
â”‚
â”œâ”€ IMPROVEMENTS (Feb 23)
â”‚  â”œâ”€ WARM_UP_INTEGRATION.md     Warm-up implementation
â”‚  â”œâ”€ EXTENDED_SUITE_DISABLEMENT.md   Extended phase safety
â”‚  â””â”€ ROUTING_DECISIONS.md       Auto-routing enforcement
â”‚
â”œâ”€ DATA & HISTORY
â”‚  â”œâ”€ meta_loop_history.json     [Layer 3] Long-term trends
â”‚  â”œâ”€ supervisor_runs/           [Layer 2] Run artifacts
â”‚  â”‚   â””â”€ {run_id}/
â”‚  â”‚       â”œâ”€ manifest.json      Run metadata + variance
â”‚  â”‚       â””â”€ summary.json       Aggregated results
â”‚  â”œâ”€ harness_feedback.json      [Layer 3] Latest recommendations
â”‚  â”œâ”€ routing_config.json        [Layer 3] Routing rules (new)
â”‚  â””â”€ routing_decisions.log      [Layer 3] Audit trail (new)
â”‚
â”œâ”€ DOCUMENTATION
â”‚  â”œâ”€ ARCHITECTURE.md            System design
â”‚  â”œâ”€ ARCHITECTURE_VISUAL_GUIDE.md   This file
â”‚  â”œâ”€ META_LEARNINGS.md          Discoveries & learnings
â”‚  â”œâ”€ INFRASTRUCTURE_VARIANCE_ANALYSIS.md   Root cause analysis
â”‚  â”œâ”€ RECURSIVE_IMPROVEMENT_STRATEGY.md   Self-improvement loop
â”‚  â”œâ”€ EXTENDED_LFM_VERDICT.md    Extended suite findings
â”‚  â””â”€ SELF_OPTIMIZING_REPORT.md  [Layer 4] Human summary
â”‚
â””â”€ TESTS (Verification)
   â”œâ”€ warm_up_test.py            Warm-up effectiveness
   â”œâ”€ extended_suite_safety_test.py   Routing safety
   â””â”€ routing_test.py            Routing enforcement
```

---

## 8. Key Metrics Dashboard

```
                  BENCHMARK HARNESS METRICS
        Last Updated: 2026-02-23 06:03 UTC+1

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ LFM ATOMIC PHASE                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Baseline Accuracy:    66.7% (native)    â”‚
â”‚ Best Variant:         83.3% (atomic)    â”‚
â”‚ Improvement:          +16.6%            â”‚
â”‚ Variance:             0.0               â”‚
â”‚ Cold-Start Pattern:   [F,F,P,P,P,P,P] âœ“â”‚
â”‚ Warm-Up Benefit:      +30% (expected)   â”‚
â”‚ Status:               âœ“ VIABLE          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ LFM EXTENDED PHASE                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Baseline Accuracy:    0%                â”‚
â”‚ Variance:             0% (consistent)   â”‚
â”‚ Root Cause:           Model limit       â”‚
â”‚ Improvement Path:     None              â”‚
â”‚ Fallback Model:       claude-haiku âœ“    â”‚
â”‚ Fallback Accuracy:    100%              â”‚
â”‚ Status:               âŒ DISABLED       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ HARNESS HEALTH                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Policy Gates:         100% pass rate âœ“  â”‚
â”‚ Feedback Loop:        Working âœ“         â”‚
â”‚ Variance Detection:   Working âœ“         â”‚
â”‚ Routing Enforcement:  Ready (pending)   â”‚
â”‚ Baseline Trend:       Improving âœ“       â”‚
â”‚ Self-Healing:         In Progress       â”‚
â”‚ Status:               ğŸŸ¡ IMPROVING      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 9. Quick Reference: What Each File Does

| File | Purpose | Inputs | Outputs |
|------|---------|--------|---------|
| `run_benchmark.py` | Execute model on prompts | model, phase, variant | accuracy.json |
| `benchmark_supervisor.py` | Run N times, detect variance | job config, N=7 | variance_analysis.json |
| `meta_harness_loop.py` | Orchestrate cycles | baseline + candidates | policy_decisions.json |
| `self_optimizing_policy.py` | Apply decision gates | candidate results | promote/hold/reject |
| `harness_feedback_loop.py` | Generate recommendations | supervisor runs | harness_feedback.json |
| `routing_enforcer.py` | Apply routing decisions | recommendations | routing_config.json |
| `meta_loop_history.json` | Long-term trends | cycle results | pattern analysis |
| `routing_decisions.log` | Audit trail | routing enforcement | traceable decisions |

---

## 10. Common Tasks

```
Task: Run a single benchmark
  $ python3 run_benchmark.py lfm2.5-thinking:1.2b atomic native_api

Task: Run with warm-up enabled
  $ python3 run_benchmark.py ... --enable-warmup

Task: Run full meta-harness cycle
  $ python3 meta_harness_loop.py --baseline "..." --candidates "..." "..." --cycles 1

Task: Generate routing recommendations
  $ python3 harness_feedback_loop.py

Task: Apply routing rules
  $ python3 routing_enforcer.py

Task: View latest report
  $ cat SELF_OPTIMIZING_REPORT.md

Task: Check routing audit trail
  $ tail -50 routing_decisions.log

Task: View improvement history
  $ jq '.[] | {cycle, baseline_acc: .baseline.median_accuracy}' meta_loop_history.json
```

---

**Last Updated:** 2026-02-23  
**Status:** Architecture complete, implementations ready  
**Next Step:** Run Phase 1 improvements (warm-up + routing)
