{
  "benchmark_session": {
    "date": "2026-02-19",
    "duration_hours": 8,
    "methodology": "MikeVeerman tool-calling-benchmark (modified)",
    "phases": ["atomic", "extended", "phase2"],
    "models_tested": 5
  },
  
  "atomic_results": {
    "description": "P1-P12: Single-prompt tool-calling decisions (action, restraint, judgment)",
    "summary": {
      "total_models": 4,
      "passed_threshold": 3,
      "failed_threshold": 1
    },
    "by_model": {
      "lfm2.5-thinking:1.2b": {
        "accuracy": 0.9555,
        "passed": 11,
        "total": 12,
        "restraint_score": 1.0,
        "wrong_tool_avoidance": 0.8333,
        "avg_latency_ms": 31973,
        "failed_prompts": ["P7"],
        "status": "PRODUCTION_READY"
      },
      "mistral:7b": {
        "accuracy": 0.6667,
        "passed": 8,
        "total": 12,
        "restraint_score": 0.83,
        "wrong_tool_avoidance": 0.6667,
        "avg_latency_ms": 21380,
        "failed_prompts": ["P7", "P10", "P11", "P12"],
        "status": "QUALIFIED_FOR_EXTENDED"
      },
      "qwen2.5:3b": {
        "accuracy": 0.6222,
        "passed": 7,
        "total": 12,
        "restraint_score": 0.33,
        "wrong_tool_avoidance": 0.6667,
        "avg_latency_ms": 6304,
        "failed_prompts": ["P4", "P6", "P9", "P10", "P11", "P12"],
        "status": "UNSAFE_HOLD_FOR_PHASE2_VALIDATION"
      },
      "gpt-oss:latest": {
        "accuracy": 0.4167,
        "passed": 5,
        "total": 12,
        "restraint_score": null,
        "wrong_tool_avoidance": null,
        "avg_latency_ms": 24796,
        "failed_prompts": ["P3", "P7", "P8", "P9", "P10", "P11", "P12"],
        "timeouts": ["P7", "P9", "P10", "P11", "P12"],
        "status": "ISSUES_TIMEOUT_PERFORMANCE"
      }
    }
  },
  
  "extended_results": {
    "description": "P13-P30: Multi-turn conversation, problem-solving, state tracking",
    "by_model": {
      "mistral:7b": {
        "accuracy": 0.4444,
        "passed": 8,
        "total": 18,
        "by_category": {
          "multi_turn": {"passed": 3, "total": 6, "accuracy": 0.5},
          "problem_solving": {"passed": 2, "total": 6, "accuracy": 0.3333},
          "state_tracking": {"passed": 3, "total": 6, "accuracy": 0.5}
        },
        "failed_prompts": ["P13", "P15", "P16", "P18", "P19", "P21", "P22", "P24", "P25", "P30"],
        "avg_latency_ms": 38500,
        "delta_vs_atomic": -0.223,
        "status": "MULTI_TURN_DIFFICULT"
      }
    }
  },
  
  "phase2_results": {
    "description": "Per-model harness variants (corrected timeout, per-model system prompts)",
    "variants_tested": ["atomic"],
    "by_model": {
      "lfm2.5-thinking:1.2b": {
        "variant": "bracket_notation",
        "accuracy": null,
        "status": "IN_PROGRESS"
      },
      "mistral:7b": {
        "variant": "conciseness_restraint",
        "accuracy": null,
        "status": "IN_PROGRESS"
      },
      "gpt-oss:latest": {
        "variant": "timeout_corrected",
        "accuracy": null,
        "status": "IN_PROGRESS"
      },
      "qwen2.5:3b": {
        "variant": "safety_first",
        "accuracy": null,
        "status": "IN_PROGRESS"
      }
    }
  },
  
  "recommendations": {
    "fallback_model": {
      "model": "lfm2.5-thinking:1.2b",
      "reason": "95.55% accuracy, perfect restraint (1.0), safe for production",
      "implementation": "Update openclaw.json LOCAL_TOOL_CALLING.primary to lfm2.5:1.2b",
      "variant": "bracket_notation with context awareness"
    },
    "candidates_for_phase3": [
      {
        "model": "lfm2.5-thinking:1.2b",
        "priority": "HIGH",
        "goal": "Validate consistency on extended (P13-P30)",
        "expected": "Maintain ≥95%"
      },
      {
        "model": "mistral:7b",
        "priority": "HIGH",
        "goal": "Validate Phase 2 variant improvement, test extended",
        "expected": "Improve from 66.7%, target ≥75%"
      }
    ],
    "skip_phase3": [
      {
        "model": "qwen2.5:3b",
        "reason": "Restraint 0.33 (unsafe). Hold pending Phase 2 variant results."
      },
      {
        "model": "gpt-oss:latest",
        "reason": "41.7% accuracy + timeout issues. Issues are harness/system, not model capability."
      }
    ]
  },
  
  "key_insights": [
    "Safety (restraint) is equally important as accuracy for production fallback",
    "Extended suite (multi-turn) drops all model scores 20-30%, indicating real-world is harder",
    "Per-model harness variants are necessary; one-size-fits-all fails",
    "Native Ollama tools API is critical; fallback JSON parsing breaks models",
    "Signal-based timeout prevents hangs; param-based timeout doesn't work"
  ],
  
  "artifacts": {
    "atomic_results_json": "/root/.openclaw/workspace/bench/local_models_native_api_results.json",
    "extended_results_json": "/root/.openclaw/workspace/bench/extended_phase1_mistral.json",
    "phase2_harness_config": "/root/.openclaw/workspace/bench/harness/phase2_config.json",
    "consolidated_runner": "/root/.openclaw/workspace/bench/run_benchmark.py",
    "results_aggregator": "/root/.openclaw/workspace/bench/aggregate_results.py"
  },
  
  "next_steps": [
    "Wait for Phase 2 (5 models) completion (~40 min remaining)",
    "Run aggregate_results.py to generate final comparison matrices",
    "Update this template with Phase 2 results",
    "Create PR with consolidated findings",
    "Update openclaw.json fallback chain",
    "Execute Phase 3 (retry survivors with locked Phase 2 variants)"
  ]
}
